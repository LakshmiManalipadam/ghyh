{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QluWXyUOboCz"
      },
      "outputs": [],
      "source": [
        "!pip install xlsxwriter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/final_lagged.xlsx'  # Specify your file path\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Create a new Excel writer object\n",
        "with pd.ExcelWriter('knn_lagged.xlsx', engine='xlsxwriter') as writer:\n",
        "\n",
        "    # Iterate over all sheets\n",
        "    for sheet_name in xls.sheet_names:\n",
        "        # Read each sheet into a DataFrame\n",
        "        df = pd.read_excel(xls, sheet_name=sheet_name)\n",
        "\n",
        "        # Create a mask for rows where all values are missing (excluding 'Timestamp')\n",
        "        if 'Timestamp' in df.columns:\n",
        "            df_no_timestamp = df.drop(columns=['Timestamp'])\n",
        "        else:\n",
        "            df_no_timestamp = df\n",
        "\n",
        "        all_missing_mask = df_no_timestamp.isnull().all(axis=1)\n",
        "\n",
        "        # Apply KNN imputation to rows with partial missing values\n",
        "        if df_no_timestamp.isnull().values.any():\n",
        "            # Create a copy for KNN imputation\n",
        "            df_knn = df_no_timestamp.copy()\n",
        "\n",
        "            # Apply KNN imputation\n",
        "            imputer = KNNImputer(n_neighbors=5)\n",
        "            df_knn_imputed = pd.DataFrame(imputer.fit_transform(df_knn), columns=df_knn.columns, index=df.index)\n",
        "\n",
        "            # Restore rows where all values were missing\n",
        "            df_knn_imputed[all_missing_mask] = df_no_timestamp[all_missing_mask]\n",
        "\n",
        "            # Reinsert the 'Timestamp' column back into the DataFrame\n",
        "            if 'Timestamp' in df.columns:\n",
        "                df_knn_imputed.insert(0, 'Timestamp', df['Timestamp'])\n",
        "\n",
        "            # Convert 'Timestamp' back to datetime format\n",
        "            if 'Timestamp' in df_knn_imputed.columns:\n",
        "                df_knn_imputed['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "            # Write the KNN imputed DataFrame back to the Excel writer\n",
        "            df_knn_imputed.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "        else:\n",
        "            # If no NaN values are present, just write the original DataFrame\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    # Save the output\n",
        "    writer.close()\n",
        "\n",
        "print(\"KNN imputation applied for partial missing data. Fully missing rows left unchanged. Output saved to 'knn_interpolated_output.xlsx'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/knn_lagged.xlsx'  # Specify your file path\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Create a new Excel writer object\n",
        "with pd.ExcelWriter('imputed_lagged.xlsx', engine='xlsxwriter') as writer:\n",
        "\n",
        "    # Iterate over all sheets\n",
        "    for sheet_name in xls.sheet_names:\n",
        "        # Read each sheet into a DataFrame\n",
        "        df = pd.read_excel(xls, sheet_name=sheet_name)\n",
        "\n",
        "        # Apply linear interpolation for missing values\n",
        "        df_interpolated = df.interpolate(method='linear', limit_direction='both')\n",
        "\n",
        "        # Write the interpolated DataFrame back to the Excel writer\n",
        "        df_interpolated.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    # Save the output\n",
        "    writer.close()\n",
        "\n",
        "print(\"Linear interpolation applied and saved to 'interpolated_output.xlsx'\")\n"
      ],
      "metadata": {
        "id": "DdVOQdFfbycF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Excel file\n",
        "file_path ='/content/Correlations(pm10_including zero).xlsx' # Replace with your file path\n",
        "\n",
        "# List of seasons for labeling\n",
        "seasons = ['corr_summer', 'corr_monsoon', 'corr_post_mons', 'corr_winter']\n",
        "\n",
        "# Read all sheets into a dictionary of DataFrames\n",
        "sheets_dict = pd.read_excel(file_path, sheet_name=None)\n",
        "\n",
        "# Create a box plot for each sheet (variable)\n",
        "for variable, df in sheets_dict.items():\n",
        "    # Assuming the DataFrame has stations as rows and seasons as columns\n",
        "    data_to_plot = df[seasons]\n",
        "\n",
        "    # Create a box plot for the current variable\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(data=data_to_plot)\n",
        "\n",
        "    # Set the title and labels\n",
        "    plt.title(f'Box Plot for {variable} for 2023', fontsize=16)\n",
        "    plt.xlabel('Season', fontsize=12)\n",
        "    plt.ylabel('Correlation with PM10', fontsize=12)\n",
        "\n",
        "    # Save the plot or show it\n",
        "    plt.savefig(f'{variable}_boxplot(2023)_new.png')  # Saves the plot\n",
        "    plt.show()  # To display the plot\n"
      ],
      "metadata": {
        "id": "Qi4JkKs_cFhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/imputed_all_cites(23)_new.xlsx'  # Update this with the actual file path\n",
        "excel_file = pd.ExcelFile(file_path)\n",
        "\n",
        "# Define the timestamp range\n",
        "start_timestamp = '2023-10-01'  # Start of the range\n",
        "end_timestamp = '2023-11-30'  # End of the range\n",
        "\n",
        "# Initialize a dictionary to store normalized data\n",
        "normalized_sheets = {}\n",
        "\n",
        "# Iterate through each sheet in the Excel file\n",
        "for sheet_name in excel_file.sheet_names:\n",
        "    # Read the current sheet into a DataFrame\n",
        "    df = excel_file.parse(sheet_name)\n",
        "\n",
        "    # Convert 'Timestamp' column to datetime format\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "    # Filter data for the specific timestamp range\n",
        "    df_filtered = df[(df['Timestamp'] >= start_timestamp) & (df['Timestamp'] <= end_timestamp)]\n",
        "\n",
        "    # Remove the 'PM10' column\n",
        "    df_filtered = df_filtered.drop(columns=['PM2.5 (µg/m³)'], errors='ignore')\n",
        "\n",
        "    # Define variables to normalize (all remaining columns except 'Timestamp')\n",
        "    variables_to_normalize = df_filtered.columns[1:]  # Exclude 'Timestamp'\n",
        "\n",
        "    # Normalize each variable (PM2.5 and the other 9 variables) within the filtered time range\n",
        "    df_normalized = df_filtered.copy()\n",
        "    df_normalized[variables_to_normalize] = df_filtered[variables_to_normalize].apply(\n",
        "        lambda x: (x - x.mean()) / x.std()\n",
        "    )\n",
        "\n",
        "    # Store the normalized DataFrame in the dictionary\n",
        "    normalized_sheets[sheet_name] = df_normalized\n",
        "\n",
        "# Save the normalized sheets back into a new Excel file\n",
        "output_file_path = 'normalized_post_monsoon(pm10)_new.xlsx'  # Update with your desired output file path\n",
        "with pd.ExcelWriter(output_file_path) as writer:\n",
        "    for sheet_name, df_normalized in normalized_sheets.items():\n",
        "        df_normalized.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "print(\"Normalization complete for the specified timestamp range. The file has been saved as:\", output_file_path)"
      ],
      "metadata": {
        "id": "BQoacB4tcQ8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/imputed_all_cites(23)_new.xlsx'  # Update this with the actual file path\n",
        "excel_file = pd.ExcelFile(file_path)\n",
        "\n",
        "# Define the timestamp ranges\n",
        "timestamp_ranges = [\n",
        "    ('2023-12-01', '2023-12-31'),\n",
        "    ('2023-01-01', '2023-02-28')\n",
        "]\n",
        "\n",
        "# Initialize a dictionary to store normalized data\n",
        "normalized_sheets = {}\n",
        "\n",
        "# Iterate through each sheet in the Excel file\n",
        "for sheet_name in excel_file.sheet_names:\n",
        "    # Read the current sheet into a DataFrame\n",
        "    df = excel_file.parse(sheet_name)\n",
        "\n",
        "    # Convert 'Timestamp' column to datetime format\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "    # Filter data for the specific timestamp ranges\n",
        "    df_filtered = pd.concat([\n",
        "        df[(df['Timestamp'] >= start) & (df['Timestamp'] <= end)]\n",
        "        for start, end in timestamp_ranges\n",
        "    ])\n",
        "\n",
        "    # Remove the 'PM10' column\n",
        "    df_filtered = df_filtered.drop(columns=['PM2.5 (µg/m³)'], errors='ignore')\n",
        "\n",
        "    # Define variables to normalize (all remaining columns except 'Timestamp')\n",
        "    variables_to_normalize = df_filtered.columns[1:]  # Exclude 'Timestamp'\n",
        "\n",
        "    # Normalize each variable (PM2.5 and the other 9 variables) within the filtered time range\n",
        "    df_normalized = df_filtered.copy()\n",
        "    df_normalized[variables_to_normalize] = df_filtered[variables_to_normalize].apply(\n",
        "        lambda x: (x - x.mean()) / x.std()\n",
        "    )\n",
        "\n",
        "    # Store the normalized DataFrame in the dictionary\n",
        "    normalized_sheets[sheet_name] = df_normalized\n",
        "\n",
        "# Save the normalized sheets back into a new Excel file\n",
        "output_file_path = 'normalized_winter(pm10)_new.xlsx'  # Update with your desired output file path\n",
        "with pd.ExcelWriter(output_file_path) as writer:\n",
        "    for sheet_name, df_normalized in normalized_sheets.items():\n",
        "        df_normalized.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "print(\"Normalization complete for the specified timestamp ranges. The file has been saved as:\", output_file_path)"
      ],
      "metadata": {
        "id": "_aKGEUp_cYF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Excel file with multiple sheets\n",
        "file_path = '/content/normalized_post_monsoon(pm10)_new.xlsx'  # Replace with your file path\n",
        "excel_data = pd.read_excel(file_path, sheet_name=None)  # Load all sheets into a dictionary\n",
        "\n",
        "# Define the post-monsoon period\n",
        "start_date = '2023-10-01'\n",
        "end_date = '2023-11-30'\n",
        "\n",
        "# Variables of interest (independent variables and PM2.5)\n",
        "independent_vars = ['NO2 (µg/m³)', 'SO2 (µg/m³)', 'CO (mg/m³)', 'Ozone (µg/m³)', 'AT (°C)', 'RH (%)', 'WS (m/s)', 'WD (deg)']\n",
        "dependent_var = 'PM10 (µg/m³)'\n",
        "\n",
        "# Initialize dictionaries to store individual sheet data\n",
        "R_xx_dict = {}\n",
        "R_xy_dict = {}\n",
        "result_dict = {}\n",
        "\n",
        "# Loop through each sheet in the Excel file\n",
        "for sheet_name, df in excel_data.items():\n",
        "    # Ensure the timestamp is in datetime format\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "    # Filter the data based on the post-monsoon period\n",
        "    post_monsoon_data = df[(df['Timestamp'] >= start_date) & (df['Timestamp'] <= end_date)]\n",
        "\n",
        "    # Collect the independent variables and dependent variable data\n",
        "    independent_data = post_monsoon_data[independent_vars]\n",
        "    dependent_data = post_monsoon_data[dependent_var]\n",
        "\n",
        "    # Calculate correlation matrix R_xx for the independent variables\n",
        "    R_xx = independent_data.corr()\n",
        "    R_xx_dict[sheet_name] = R_xx  # Store R_xx in dictionary\n",
        "\n",
        "    # Calculate correlation matrix R_xy between PM2.5 and independent variables\n",
        "    R_xy = independent_data.corrwith(dependent_data)\n",
        "    R_xy = pd.DataFrame(R_xy, columns=[dependent_var])\n",
        "    R_xy_dict[sheet_name] = R_xy  # Store R_xy in dictionary\n",
        "\n",
        "    # Calculate the inverse of R_xx\n",
        "    R_xx_inv = np.linalg.inv(R_xx)\n",
        "\n",
        "    # Multiply R_xx inverse with R_xy\n",
        "    result = pd.DataFrame(R_xx_inv @ R_xy, columns=[dependent_var])\n",
        "    result_dict[sheet_name] = result  # Store result in dictionary\n",
        "\n",
        "# Write R_xx to one Excel file with multiple sheets\n",
        "with pd.ExcelWriter('R_xx_post_monsoon(pm10)_new.xlsx') as writer:\n",
        "    for sheet_name, R_xx in R_xx_dict.items():\n",
        "        R_xx.to_excel(writer, sheet_name=sheet_name)\n",
        "\n",
        "# Write R_xy to another Excel file with multiple sheets\n",
        "with pd.ExcelWriter('R_xy_post_monsoon(pm10)_new.xlsx') as writer:\n",
        "    for sheet_name, R_xy in R_xy_dict.items():\n",
        "        R_xy.to_excel(writer, sheet_name=sheet_name)\n",
        "\n",
        "# Write R_xx_inv * R_xy to a third Excel file with multiple sheets\n",
        "with pd.ExcelWriter('R_xx_inv_times_R_xy_post_monsoon(pm10)_new.xlsx') as writer:\n",
        "    for sheet_name, result in result_dict.items():\n",
        "        result.to_excel(writer, sheet_name=sheet_name)\n",
        "\n",
        "print(\"Results saved to separate Excel files successfully!\")\n"
      ],
      "metadata": {
        "id": "wU_YJ8tFcfPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Excel file with multiple sheets\n",
        "file_path = '/content/normalized_winter(pm10)_new.xlsx'  # Replace with your file path\n",
        "excel_data = pd.read_excel(file_path, sheet_name=None)  # Load all sheets into a dictionary\n",
        "\n",
        "# Define the winter periods\n",
        "winter_period1_start = '2023-12-01'\n",
        "winter_period1_end = '2023-12-31'\n",
        "winter_period2_start = '2023-01-01'\n",
        "winter_period2_end = '2023-02-28'\n",
        "\n",
        "# Variables of interest (independent variables and PM2.5)\n",
        "independent_vars = ['NO2 (µg/m³)', 'SO2 (µg/m³)', 'CO (mg/m³)', 'Ozone (µg/m³)', 'AT (°C)', 'RH (%)', 'WS (m/s)', 'WD (deg)']\n",
        "dependent_var = 'PM10 (µg/m³)'\n",
        "\n",
        "# Initialize dictionaries to store individual sheet data\n",
        "R_xx_dict = {}\n",
        "R_xy_dict = {}\n",
        "result_dict = {}\n",
        "\n",
        "# Loop through each sheet in the Excel file\n",
        "for sheet_name, df in excel_data.items():\n",
        "    # Ensure the timestamp is in datetime format\n",
        "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "    # Filter the data based on the two winter periods\n",
        "    winter_data = df[\n",
        "        ((df['Timestamp'] >= winter_period1_start) & (df['Timestamp'] <= winter_period1_end)) |\n",
        "        ((df['Timestamp'] >= winter_period2_start) & (df['Timestamp'] <= winter_period2_end))\n",
        "    ]\n",
        "\n",
        "    # Collect the independent variables and dependent variable data\n",
        "    independent_data = winter_data[independent_vars]\n",
        "    dependent_data = winter_data[dependent_var]\n",
        "\n",
        "    # Calculate correlation matrix R_xx for the independent variables\n",
        "    R_xx = independent_data.corr()\n",
        "    R_xx_dict[sheet_name] = R_xx  # Store R_xx in dictionary\n",
        "\n",
        "    # Calculate correlation matrix R_xy between PM2.5 and independent variables\n",
        "    R_xy = independent_data.corrwith(dependent_data)\n",
        "    R_xy = pd.DataFrame(R_xy, columns=[dependent_var])\n",
        "    R_xy_dict[sheet_name] = R_xy  # Store R_xy in dictionary\n",
        "\n",
        "    # Calculate the inverse of R_xx\n",
        "    R_xx_inv = np.linalg.inv(R_xx)\n",
        "\n",
        "    # Multiply R_xx inverse with R_xy\n",
        "    result = pd.DataFrame(R_xx_inv @ R_xy, columns=[dependent_var])\n",
        "    result_dict[sheet_name] = result  # Store result in dictionary\n",
        "\n",
        "# Write R_xx to one Excel file with multiple sheets\n",
        "with pd.ExcelWriter('R_xx_winter(pm10)_new.xlsx') as writer:\n",
        "    for sheet_name, R_xx in R_xx_dict.items():\n",
        "        R_xx.to_excel(writer, sheet_name=sheet_name)\n",
        "\n",
        "# Write R_xy to another Excel file with multiple sheets\n",
        "with pd.ExcelWriter('R_xy_winter(pm10)_new.xlsx') as writer:\n",
        "    for sheet_name, R_xy in R_xy_dict.items():\n",
        "        R_xy.to_excel(writer, sheet_name=sheet_name)\n",
        "\n",
        "# Write R_xx_inv * R_xy to a third Excel file with multiple sheets\n",
        "with pd.ExcelWriter('R_xx_inv_times_R_xy_winter(pm10)_new.xlsx') as writer:\n",
        "    for sheet_name, result in result_dict.items():\n",
        "        result.to_excel(writer, sheet_name=sheet_name)\n",
        "\n",
        "print(\"Results saved to separate Excel files successfully!\")\n"
      ],
      "metadata": {
        "id": "IXItOFArcmPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/imputed_all_cites(23)_new.xlsx'\n",
        "excel_data = pd.ExcelFile(file_path)\n",
        "sheet_names = excel_data.sheet_names\n",
        "\n",
        "# Initialize an output dictionary to store VIF results\n",
        "vif_results = {}\n",
        "\n",
        "# Define the date range\n",
        "start_date = '2023-03-01'\n",
        "end_date = '2023-05-31'\n",
        "\n",
        "for sheet in sheet_names:\n",
        "    # Load the sheet\n",
        "    data = excel_data.parse(sheet)\n",
        "\n",
        "    # Ensure the timestamp column is in datetime format\n",
        "    data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
        "\n",
        "    # Filter the data for the specific date range\n",
        "    filtered_data = data[(data['Timestamp'] >= start_date) & (data['Timestamp'] <= end_date)]\n",
        "\n",
        "    # Drop timestamp and PM10 columns\n",
        "    filtered_data = filtered_data.drop(columns=['Timestamp', 'PM10 (µg/m³)'])\n",
        "\n",
        "    # Separate PM2.5 as the dependent variable\n",
        "    dependent_var = 'PM2.5 (µg/m³)'\n",
        "    filtered_data = filtered_data.drop(columns=[dependent_var])\n",
        "\n",
        "    # Add a constant to the data for VIF calculation\n",
        "    X = add_constant(filtered_data)\n",
        "\n",
        "    # Calculate VIF for each variable\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data['Variable'] = X.columns\n",
        "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    # Store the VIF results in the output dictionary\n",
        "    vif_results[sheet] = vif_data\n",
        "\n",
        "# Save the results to an Excel file\n",
        "output_path = 'vif_results_summer.xlsx'\n",
        "with pd.ExcelWriter(output_path) as writer:\n",
        "    for sheet, vif_data in vif_results.items():\n",
        "        vif_data.to_excel(writer, sheet_name=sheet, index=False)\n",
        "\n",
        "print(f\"VIF results saved to {output_path}\")"
      ],
      "metadata": {
        "id": "09m4xNFFdZVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create a DataFrame with your data\n",
        "data = {\n",
        "        'Factor': ['NO2', 'SO2', 'CO', 'AT', 'RH', 'WS'],\n",
        "        'Direct': [45, None, 43, 31, None, 19],\n",
        "        'Indirect': [17, None, 8, 33, None, 44],\n",
        "        'Both': [26, None, 43, 17, None, 44],\n",
        "        'No effect': [11, None,5, 19, None, 20],\n",
        "        'Correlation': ['+ve', 'zero', '+ve', '-ve', 'zero', '-ve']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 2. Reshape the data from wide to long form for plotting\n",
        "df_melt = df.melt(\n",
        "    id_vars=['Factor','Correlation'],\n",
        "    value_vars=['Direct','Indirect','Both','No effect'],\n",
        "    var_name='Category',\n",
        "    value_name='Value'\n",
        ")\n",
        "\n",
        "# 3. Map correlation signs to colors\n",
        "color_map = {\n",
        "    '+ve':  'blue',\n",
        "    '-ve':  'red',\n",
        "    'zero': 'gray'\n",
        "}\n",
        "\n",
        "# 4. Define the order for categories & factors (to match your layout)\n",
        "categories = ['Direct','Indirect','Both','No effect']\n",
        "factors    = ['NO2','SO2','CO','AT','WS','RH']\n",
        "\n",
        "# 5. Convert categories and factors to numeric positions\n",
        "x_positions = {cat: i for i, cat in enumerate(categories)}\n",
        "y_positions = {fac: i for i, fac in enumerate(factors)}\n",
        "\n",
        "# 6. Create the plot\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "\n",
        "# Enable grid lines behind the scatter points\n",
        "ax.set_axisbelow(True)\n",
        "ax.xaxis.grid(True, color='lightgray', linewidth=0.5)\n",
        "ax.yaxis.grid(True, color='lightgray', linewidth=0.5)\n",
        "\n",
        "# 7. Plot bubbles or dashes\n",
        "for _, row in df_melt.iterrows():\n",
        "    cat = row['Category']\n",
        "    fac = row['Factor']\n",
        "    val = row['Value']\n",
        "    cor = row['Correlation']\n",
        "\n",
        "    x_val = x_positions[cat]\n",
        "    y_val = y_positions[fac]\n",
        "\n",
        "    # If value is missing or zero, show a dash\n",
        "    if pd.isnull(val) or val == 0:\n",
        "        ax.text(\n",
        "            x_val, y_val,\n",
        "            '-',\n",
        "            ha='center', va='center',\n",
        "            fontsize=12\n",
        "        )\n",
        "        continue\n",
        "\n",
        "    # Otherwise, draw a bubble\n",
        "    bubble_size  = val * 30  # Scale circle size by the percentage\n",
        "    bubble_color = color_map.get(cor, 'gray')\n",
        "\n",
        "    scatter = ax.scatter(\n",
        "        x_val, y_val,\n",
        "        s=bubble_size,\n",
        "        c=bubble_color,\n",
        "        alpha=0.6,\n",
        "        edgecolors='k'\n",
        "    )\n",
        "\n",
        "    # Convert the value to integer to avoid floats, then add a \"%\" sign\n",
        "    ax.text(\n",
        "        x_val, y_val,\n",
        "        f\"{int(val)}%\",\n",
        "        ha='center',\n",
        "        va='center',\n",
        "        fontsize=6.5,\n",
        "        color='white',    # or 'black', depending on your preference\n",
        "        weight='bold'     # make it bold if desired\n",
        "    )\n",
        "\n",
        "# 8. Configure axis ticks and labels\n",
        "ax.set_xticks(range(len(categories)))\n",
        "ax.set_xticklabels(categories)\n",
        "ax.set_yticks(range(len(factors)))\n",
        "ax.set_yticklabels(factors)\n",
        "\n",
        "ax.set_xlim(-0.5, len(categories) - 0.5)\n",
        "ax.set_ylim(-0.5, len(factors) - 0.5)\n",
        "\n",
        "ax.set_xlabel('Category')\n",
        "ax.set_ylabel('Factor')\n",
        "ax.set_title('Winter_PM10')\n",
        "\n",
        "# 9. Place the legend outside the main plotting area\n",
        "for corr_label, color in color_map.items():\n",
        "    ax.scatter([], [], c=color, alpha=0.6, edgecolors='k', label=corr_label)\n",
        "ax.legend(\n",
        "    title='Correlation',\n",
        "    loc='center left',       # anchor the legend to the left center of the bounding box\n",
        "    bbox_to_anchor=(1, 0.5)  # place the bounding box to the right of the axes\n",
        ")\n",
        "\n",
        "# Ensure enough space on the right for the legend\n",
        "plt.tight_layout(rect=[0, 0, 0.8, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3NjqP4R0dxqc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}